# ğŸ›³ï¸ Titanic Survival Prediction - End-to-End Advanced Data Analysis & Prediction

![titanic](assets/titanic.png)

This project dives deep into the **Titanic Dataset** to uncover hidden insights about the passengers â€” who survived, why, and how different social, demographic, and ticket-based factors influenced survival chances.

The project walks through **data cleaning, feature engineering, exploratory data analysis (EDA)**, and finally **machine learning modeling** to predict survival probabilities.

---

## ğŸ“ Dataset
The dataset used is the **Titanic-Dataset.csv**, which contains passenger details such as:
- Demographics (Age, Sex, Name, etc.)
- Travel information (Ticket, Fare, Cabin, Embarked)
- Survival status (0 = Did not survive, 1 = Survived)

---

## âš™ï¸ Steps Performed

### 1. **Data Cleaning & Preprocessing**
- Dropped unnecessary column `PassengerId`.
- Filled missing values in:
  - `Embarked` with **mode**.
  - `Age` with **median grouped by Title** of passengers extracted from `Name` feature.
  - `Deck` predicted using a **Random Forest Classifier**.
- Extracted meaningful information from:
  - `Name` â†’ Extracted **Title (Mr, Mrs, Miss, etc.)**.
  - `Cabin` â†’ Extracted **Deck**.
  - `Ticket` â†’ Created **Ticket Group Size** to identify social context.
- Created new feature **Family_Size = 1 + Parch + SibSp**.
- Engineered **Social_Context (Grouping)** as:
  - Alone  
  - Small Family  
  - Large Family  
  - Group with Non-Family  
- Categorized passengers under 16 years as **child** in the `Sex` column.

---

### 2. **Feature Engineering Highlights**
| Feature | Description |
|----------|--------------|
| `Title` | Extracted from Name, grouped into 6 categories (Mr, Mrs, Miss, Master, Military, Other) |
| `Deck` | Extracted from Cabin and predicted missing values |
| `Family_Size` | Count of family members including passenger |
| `Grouping` | Identifies whether a person is Alone, in Family, or with Non-Family group |
| `Sex` | Categorized into male, female, child |
| `Fare` | Rounded to 2 decimal points |

---

## ğŸ“Š Exploratory Data Analysis (EDA)

Below are visual insights obtained from the data exploration:

### âš« Survival Distribution
Shows overall survival ratio.
  
![Survival Pie](assets/survival_pie.png)

---

### âš« Survival by Gender
Children and women had a higher survival rate compared to men.

![survival_gender](assets/survival_gender.jpg)

---

### âš« Deck-wise Survival Rate
Certain decks had higher chances of survival (upper decks).

![Decks](assets/Decks.png)

![survival_deck](assets/survival_deck.png)

---

### âš« Age vs Survival
Younger passengers and middle-aged adults survived more than elderly.

![agesurvival](assets/agesurvival.png)

---

### âš« Passenger Class vs Survival
Higher-class passengers had better survival odds.

![classsurvival](assets/classsurvival.png)

---

### âš« Grouping (Social Context) vs Survival
Small families had the highest survival rate, while large families struggled.

![groupingsurvival](assets/groupingsurvival.png)

---

### âš« Title vs Survival
Masters (young boys) and married women (Mrs) survived most.

![titlesurvival](assets/titlesurvival.png)

---

### âš« Fare vs Survival
Higher fare correlated with higher survival chances â€” money did matter!

![faresurvival1](assets/faresurvival1.png)
![faresurvival2](assets/faresurvival2.png)

---

## ğŸ§  Machine Learning Model

Three models were trained and compared:  

![comparison](assets/comparison.png)

Random Forestt Classifier provided **82.68%** accuracy with good balance of precision and recall.  


> Random Forest Classifier was chosen as the **final model** due to the best overall performance.


---

## ğŸ§© Tech Stack

- **Python** ğŸ  
- **Pandas, NumPy** â†’ Data Wrangling  
- **Seaborn, Matplotlib** â†’ Visualization  
- **Scikit-learn** â†’ Preprocessing & Modeling  
- **XGBoost** â†’ Advanced Classification  

---

## ğŸ“ˆ Key Insights

- ğŸ’¡ **Women and Children first** policy truly reflected in survival statistics.  
- ğŸ’¡ **High fare and high class** passengers had better survival rates.  
- ğŸ’¡ **Small families** survived more often than large ones.  
- ğŸ’¡ **Deck and Title** had a significant correlation with survival.

---

## ğŸ§¾ Conclusion

After extensive **feature engineering, visualization, and modeling**, this project achieved a strong predictive performance with **Random Forest (Accuracy â‰ˆ 82.68%)**.

This workflow demonstrates how combining **domain understanding**, **data cleaning**, and **machine learning** can bring clarity to historical datasets like the Titanic.

---

## ğŸ§‘â€ğŸ’» Author
**Md Mehedi Hassan**  
Data Scientist | Researcher
ğŸ“§ mehedi3128.mhd@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/md-mehedi-hassan-65818b243) | [GitHub](https://github.com/Mehedi2154901019)

---

> â­ *If you like this project, donâ€™t forget to give it a star!*
